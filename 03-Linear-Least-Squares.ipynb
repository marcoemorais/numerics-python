{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.01 Linear Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem: Measurements Have Error\n",
    "* Measurement errors are inevitable\n",
    "* Variability can be smoothed out by averaging over more data\n",
    "* Resulting system is **overdetermined**\n",
    "  * More equations (rows) than unknowns (columns)\n",
    "\n",
    "#### Solution: Use Least Squares\n",
    "* Project higher dimensional data into lower dimensional space\n",
    "* Suppresses noise and irrelevant detail\n",
    "* Better written as $Ax \\approxeq b$\n",
    "  * Emphasis that $x$ is not exact solution\n",
    "* Solution minimizes squared 2-norm of residual\n",
    "  * $\\min_x ||r||_2^2 = \\min_x || b - Ax ||_2^2$\n",
    "\n",
    "\n",
    "What does *linear* mean?\n",
    "* If $f(t, x)$ is the function represented by $Ax = b$, then coefficients of $A$ are some power of $t$.\n",
    "$$\n",
    "f(t, x) = x_1 + x_2 t + x_3 t^2 + ... + x_n t^{n-1}\n",
    "$$\n",
    "* Non-linear counterexample.\n",
    "$$\n",
    "f(t, x) = x_1 + x_2 e^{t} + x_3 e^{t^2} + ... + x_n e^{t^{n-1}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given $m$ data points $(t_i, y_i)$ find n-vector $x$ of parameters that gives best fit to model function $f(t, x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Input data $(t_i, y_i)$.\n",
    "m = 5\n",
    "t = np.linspace(-1., 1., m)\n",
    "y = np.array([1., 0.5, 0., 0.5, 2.]).reshape(m, 1)\n",
    "\n",
    "# Solve Ax = y for x.\n",
    "A = np.column_stack((np.ones(m), t, t*t))\n",
    "x, r, _, _ = np.linalg.lstsq(A, y, rcond=None)\n",
    "\n",
    "# Compute the squared 2-norm of the residual.\n",
    "resid = y - np.matmul(A, x)\n",
    "sq2norm = np.linalg.norm(resid, ord=2)**2\n",
    "\n",
    "# Compare to the residual returned from np.linalg.lstsq.\n",
    "np.testing.assert_almost_equal(sq2norm, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the observations against the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Fit the model to a dense 1D-grid of points from [-1, 1].\n",
    "fitn = m*20\n",
    "fitx = np.linspace(-1, 1, fitn)\n",
    "fitA = np.column_stack((np.ones(fitn), fitx, fitx*fitx))\n",
    "fity = np.matmul(fitA, x)\n",
    "\n",
    "# Plot the fitted model against observations.\n",
    "plt.scatter(t, y, s=16, c='dodgerblue', label='observations')\n",
    "plt.plot(fitx, fity, c='red', label='fit')\n",
    "plt.title('Observations vs. Fit')\n",
    "plt.ylabel('y')\n",
    "plt.xlabel('t')\n",
    "plt.legend(loc=0)  # Upper left corner.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.02 Existence, Uniqueness, and Conditioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Linear least squares problem $Ax \\approxeq b$ **always** has solution.\n",
    "* Solution unique IFF columns are linearly independent aka $\\text{rank}(A) = n$ where $A$ is $m \\times n$.\n",
    "\n",
    "#### Derivation\n",
    "* To minimize the squared 2-norm of residual we need to find the derivative and set to 0.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "||r||_2^2 &= r^T r \\\\\n",
    "&= (b - Ax)^T (b - Ax) \\\\\n",
    "&= b^T b - 2 x^T A^T b + x^T A^T A x \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "* The gradient of $||r||_2^2$ set equal to 0 is aka **normal equations**.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\nabla(||r||_2^2) &= 0 \\\\\n",
    "2 A^T A x - 2 A^T b &= 0 \\\\\n",
    "A^T A x &= A^T b \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "* Since $A^TA$ is square, we can use the techniques for solving systems of linear equations to solve linear least squares problems.\n",
    "\n",
    "#### Orthogonality\n",
    "* $v_1$ and $v_2$ are othogonal when $v_1^T v_2 = 0$.\n",
    "* Value of $y = Ax$ closest to solution $b$ occurs when residual $r = b - Ax$ is orthogonal to $\\text{span}(A)$.\n",
    "  * Project higher dimensional data $b$ ($m \\times 1$) into lower dimensional space $\\text{span}(A)$ (space spanned by columns $n$).\n",
    "* Angle between $y = Ax$ and $b$ computed as:\n",
    "  * $\\text{cos}(\\theta) = \\frac{||y||_2}{||b||_2}$\n",
    "\n",
    "\n",
    "#### Orthogonal Projectors\n",
    "* $P$ is an orthgonal projector when:\n",
    "  * $P^2 = P$ aka idempotent\n",
    "  * $P^T = P$ aka symmetric\n",
    "* We can decompose any vector $v$ into 2 components:\n",
    "  * Component in $\\text{span}(P)$\n",
    "  * Component in $\\text{span}(P)^{\\perp}$ aka orthogonal to $P$\n",
    "* For least squares $P$ is an orthogonal projector onto $\\text{span}(A)$.\n",
    "  * $P = A (A^T A)^{-1} A^T$\n",
    "\n",
    "#### Pseudoinverse\n",
    "* If $A$ is $m \\times n$ and $\\text{rank}(A) = n$, then pseudoinverse is defined as the inverse of the product of the matrix and its' transpose.\n",
    "  * $A^{+} = (A^T A)^{-1} A^T$\n",
    "* Condition number of $A$ defined using pseudoinverse:\n",
    "  * $\\text{cond}(A) = ||A||_2 \\cdot ||A^{+}||_2$\n",
    "* The angle between $y = Ax$ and $b$ also bounds the relative error:\n",
    "  * $\\frac{||\\Delta{x}||}{||x||} \\leq \\text{cond}(A) \\frac{1}{\\text{cos}(\\theta)} \\frac{||\\Delta{b}||}{||b||}$\n",
    "  * When the angle $\\theta$ is small, then $\\theta \\approxeq 0$ and value of $\\text{cos}(\\theta) \\approxeq 1$.  As a result, relative error will be small.\n",
    "  * When the angle $\\theta$ is big, then relative error will be large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.03 Solving Linear Least Squares Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal Equations Method\n",
    "* If $A$ has rank $n$ then symmetric matrix $A^TA$ is positive definite.\n",
    "* Use cholesky factorization solve $Ax = b$ for $x$.\n",
    "  1. Premultiply both sides by $A^T$ to obtain $A^T A x = A^T b$.\n",
    "  2. Factorize $A^T A$ into $L L^T$ to obtain $L L^T x = A^T b$.\n",
    "  3. Solve $L z = A^Tb$ for $z$ using forward substitution.\n",
    "  4. Solve $L^T x = z$ for $x$ using back substitution.\n",
    "* This technique has problems in finite precision arithmetic.\n",
    "  * Computing $A^TA$ introduces roundoff.\n",
    "  * Sensitivity of solution is worsened.\n",
    "    * $\\text{cond}(A^T A) = [\\text{cond}(A)]^2$\n",
    "  * Normal equations method is **unstable** due to these introduced computational errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve $Ax = b$ for $x$ where $A$ is $m \\times n$ using cholesky factorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "\n",
    "# Input data $(t_i, b_i)$.\n",
    "m = 5\n",
    "t = np.linspace(-1., 1., m)\n",
    "b = np.array([1., 0.5, 0., 0.5, 2.]).reshape(m, 1)\n",
    "A = np.column_stack((np.ones(m), t, t*t))\n",
    "\n",
    "# Premultiply the left and right hand side by A^T.\n",
    "ATA = np.matmul(A.T, A)\n",
    "ATb = np.matmul(A.T, b)\n",
    "\n",
    "# Factorize A^T A into L L^T.\n",
    "LLT = np.linalg.cholesky(ATA)\n",
    "\n",
    "# Solve Lz = A^Tb for z using forward substitution.\n",
    "z = la.solve_triangular(LLT, ATb, lower=True, unit_diagonal=False)\n",
    "\n",
    "# Solve L^Tx = z for x using back substitution.\n",
    "x = la.solve_triangular(LLT.T, z, lower=False, unit_diagonal=False)\n",
    "\n",
    "# Compute the squared 2-norm of the residual.\n",
    "resid = y - np.matmul(A, x)\n",
    "sq2norm = np.linalg.norm(resid, ord=2)**2\n",
    "\n",
    "# Compare to the residual returned from np.linalg.lstsq.\n",
    "_, r, _, _ = np.linalg.lstsq(A, b, rcond=None)\n",
    "np.testing.assert_almost_equal(sq2norm, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.04 Orthogonalization Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Matrix $Q$ is orthogonal if $Q^T Q = I$.\n",
    "* Columns of orthogonal matrix are orthonormal eg orthogonal unit vectors.\n",
    "* Multiplying vector by orthogonal matrix does not change its' 2-norm.\n",
    "  * $||Qv||_2^2 = ||v||_2^2$\n",
    "* Use orthogonalization method to solve $Ax = b$ for $x$.\n",
    "  * More computationally expensive than elimination.\n",
    "  * More numerically stable than normal equations method.\n",
    "  \n",
    "#### QR Factorization\n",
    "Given $m \\times n$ matrix $A$ find an $m \\times m$ matrix $Q$.\n",
    "$$\n",
    "A = Q\n",
    "\\begin{bmatrix}\n",
    "R \\\\\n",
    "0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "where\n",
    "  * Q is an $m \\times m$ orthogonal matrix\n",
    "  * R is an $n \\times n$ upper triangular matrix\n",
    "  * 0 is an $(m-n) \\times n$ zero matrix\n",
    "\n",
    "To compute QR factorization of $A$ use one of orthogonal transformations below.\n",
    "  * Householder transformations\n",
    "  * Givens rotations\n",
    "  * Gram-Schmidt orthogonalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve $Ax = b$ for $x$ where $A$ is $m \\times n$ using QR factorization via scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "\n",
    "# Input data $(t_i, b_i)$.\n",
    "m = 5\n",
    "t = np.linspace(-1., 1., m)\n",
    "b = np.array([1., 0.5, 0., 0.5, 2.]).reshape(m, 1)\n",
    "A = np.column_stack((np.ones(m), t, t*t))\n",
    "n = A.shape[1]\n",
    "\n",
    "# Factorize A into QR.\n",
    "Q, R = np.linalg.qr(A)\n",
    "\n",
    "# Apply the same transformations to b.\n",
    "c = np.matmul(Q.T, b)\n",
    "\n",
    "# Solve Rx = c for x by back substitution.\n",
    "# NOTE(mmorais): Both R and c must be square.\n",
    "x = la.solve_triangular(R[:n,:], c[:n], lower=False, unit_diagonal=False)\n",
    "\n",
    "# Compute the squared 2-norm of the residual.\n",
    "resid = y - np.matmul(A, x)\n",
    "sq2norm = np.linalg.norm(resid, ord=2)**2\n",
    "\n",
    "# Compare to the residual returned from np.linalg.lstsq.\n",
    "_, r, _, _ = np.linalg.lstsq(A, b, rcond=None)\n",
    "np.testing.assert_almost_equal(sq2norm, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.05 Householder QR Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Householder reflection (or Householder transformation) is a transformation that takes a vector and reflects it about some plane or hyperplane.\n",
    "  * In the context of linear least squares, the reflection is used to project the vector b into the span(A).\n",
    "\n",
    "Householder transformation of the vector $v$\n",
    "$$\n",
    "H = I - 2 \\frac{v v^T}{v^T v}\n",
    "$$\n",
    "where\n",
    "* H is orthogonal ($H^T H = I$) and symmetric ($H^T = H$)\n",
    "\n",
    "Given some vector $a$ choose $v$ as:\n",
    "$$\n",
    "v = a - \\alpha e_1\n",
    "$$\n",
    "where\n",
    "* $\\alpha = \\pm ||a||_2$ with sign chosen to avoid cancellation\n",
    "* $e_1$ is the standard basis vector of the form $[1 \\quad 0 \\cdots 0]^T$\n",
    "\n",
    "The householder transform of the vector $a$ is $Ha$ computed as:\n",
    "$$\n",
    "Ha = a - 2 \\frac{v^T a}{v^T v} v\n",
    "$$\n",
    "\n",
    "The householder transform of the vector $a$ will zero out all but 1 element."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a Householder transformation on vector a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([2., 1., 2.]).reshape(3, 1)\n",
    "\n",
    "# Compute v = a - \\alpha e_1.\n",
    "alpha = np.linalg.norm(a, ord=2)\n",
    "alpha = -1. * alpha if np.sign(alpha) == 1 else alpha\n",
    "e_1 = np.zeros((a.size, 1))\n",
    "e_1[0] = 1.\n",
    "v = a - alpha * e_1\n",
    "\n",
    "# Compute H = I - 2 ((vv^T) / (v^Tv)).\n",
    "H = np.eye(a.size) - 2. * (np.dot(v, v.T)/np.dot(v.T, v))\n",
    "\n",
    "# Confirm that H is orthogonal.\n",
    "np.testing.assert_almost_equal(np.matmul(H.T, H), np.eye(a.size))\n",
    "\n",
    "# Confirm that H is symmetric.\n",
    "np.testing.assert_almost_equal(H.T, H)\n",
    "\n",
    "# Compute householder transform Ha and compare to explict Ha.\n",
    "Ha = a - 2. * (np.dot(v.T, a)/np.dot(v.T, v)) * v\n",
    "np.testing.assert_almost_equal(Ha, np.matmul(H, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Least Squares Using Householder QR Factorization\n",
    "1. Use Householder transforms to annihilate subdiagonal entries of each successive column.\n",
    "$$\n",
    "H_n \\cdots H_1 A = Q^T A =\n",
    "\\begin{bmatrix}\n",
    "R \\\\\n",
    "0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "  * Use the formula for $Ha$ to compute the *ith* transform rather than matrix multiplication.\n",
    "  * Note that $H_n \\cdots H_1 = Q^T$.\n",
    "  * Note that factorization of $A = QR$ (no transpose) where $H_1 \\cdots H_n = Q$.\n",
    "2. Apply the same set of transformations to right hand side $b$.\n",
    "$$\n",
    "H_n \\cdots H_1 b = Q^T b\n",
    "$$\n",
    "3. Solve for $x$ using backsubstitution.\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "R \\\\\n",
    "0\n",
    "\\end{bmatrix}\n",
    "x \\approxeq Q^T b\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve $Ax = b$ for $x$ where $A$ is $m \\times n$ using householder QR factorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "\n",
    "def householder_qr(A):\n",
    "    \"\"\"\n",
    "    Use householder transformations to factorize A into QR.\n",
    "    \n",
    "    Q is formed from householder transforms H_1 ... H_n I,\n",
    "    but inner loop computes Q^T = H_n ... H_1 I.  \n",
    "    \n",
    "    Since Q is orthogonal Q^T Q = I, return the transpose of \n",
    "    what is computed from the loop to provide H_1 ... H_n I.\n",
    "\n",
    "    Returns orthogonal matrix Q and upper right triangular matrix R.\n",
    "    \"\"\"\n",
    "    m, n = A.shape\n",
    "    Q, R = np.eye(m), np.copy(A)\n",
    "    for k in range(n):  # Columns.\n",
    "        alpha_k = -1. * np.sign(R[k,k]) * np.linalg.norm(R[k:,k])\n",
    "        e_k = np.zeros((m, 1))\n",
    "        e_k[k] = 1.\n",
    "        a_k = np.concatenate((e_k[:k], R[k:,k,np.newaxis]))\n",
    "        v_k = a_k - alpha_k * e_k\n",
    "        beta_k = np.dot(v_k.T, v_k)\n",
    "        Q -= 2.*(np.dot(v_k.T, Q)/beta_k) * v_k\n",
    "        if abs(beta_k) < np.finfo('d').eps:\n",
    "            continue\n",
    "        for j in range(k, n):  # Columns.\n",
    "            gamma_j = np.dot(v_k.T, R[:,j])\n",
    "            R[:,j,np.newaxis] -= (2.*gamma_j/beta_k) * v_k\n",
    "    # Q^T reverses order of transforms as described by docstring.\n",
    "    return Q.T[:,:n], R[:n,:]\n",
    "\n",
    "\n",
    "# Input data $(t_i, b_i)$.\n",
    "m = 5\n",
    "t = np.linspace(-1., 1., m)\n",
    "b = np.array([1., 0.5, 0., 0.5, 2.]).reshape(m, 1)\n",
    "A = np.column_stack((np.ones(m), t, t*t))\n",
    "n = A.shape[1]\n",
    "\n",
    "# Factorize A into QR.\n",
    "Q, R = householder_qr(A)\n",
    "np.testing.assert_almost_equal(A, np.matmul(Q, R))  # Self-check.\n",
    "\n",
    "# Apply the householder transformation to b.\n",
    "c = np.matmul(Q.T, b)\n",
    "\n",
    "# Solve Rx = c for x by back substitution.\n",
    "# NOTE(mmorais): Both R and c must be square.\n",
    "x = la.solve_triangular(R, c[:n], lower=False, unit_diagonal=False)\n",
    " \n",
    "# Compute the squared 2-norm of the residual.\n",
    "resid = y - np.matmul(A, x)\n",
    "sq2norm = np.linalg.norm(resid, ord=2)**2\n",
    "\n",
    "# Compare to the residual returned from np.linalg.lstsq.\n",
    "_, r, _, _ = np.linalg.lstsq(A, b, rcond=None)\n",
    "np.testing.assert_almost_equal(sq2norm, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.06 Givens QR Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each Givens rotation zeroes an element in the subdiagonal of the matrix, forming the R matrix. The concatenation of all the Givens rotations forms the orthogonal Q matrix.\n",
    "\n",
    "Givens rotations are expensive to compute, but unlike the householder transformations they can be parallelized.\n",
    "\n",
    "Givens QR factorization is less frequently used than householder transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.07 Gram-Schmidt QR Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gram-Schmidt Orthogonalization\n",
    "Given vectors $a_1$ and $a_2$ seek orthonormal vectors $q_1$ and $q_2$ having the same span.\n",
    "1. Normalize $a_1$ to obtain $q_1 = a_1 / ||a_1||_2$\n",
    "2. Project $a_2$ onto $q_1$ via $q_2 = a_2 - (q_1^T a_2) q_1$\n",
    "\n",
    "Implementations\n",
    "1. Classical Gram-Schmidt\n",
    "  * Orthonormalizes column-by-column\n",
    "  * Subtracts current $q_k$ from components in preceding columns\n",
    "  * Requires separate storage for $Q$ and $R$\n",
    "2. Modified Gram-Schmidt\n",
    "  * Orthonormalizes column-by-column\n",
    "  * Subtracts current $q_k$ from components in succeeding columns\n",
    "    * $R$ is built up row-by-row\n",
    "    * More numerically stable than Classical Gram-Schmidt\n",
    "  * $A$ can be modified in place to obtain $R$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve $Ax = b$ for $x$ where $A$ is $m \\times n$ using classical Gram-Schmidt QR factorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "\n",
    "def cgs_qr(A):\n",
    "    \"\"\"\n",
    "    Use classical Gram-Schmidt to factorize A into QR.\n",
    "\n",
    "    Returns orthogonal matrix Q and upper right triangular matrix R.\n",
    "    \"\"\"\n",
    "    m, n = A.shape\n",
    "    Q, R = np.eye(m), np.zeros((m, n))\n",
    "    for k in range(n):  # Columns.\n",
    "        Q[:,k] = A[:,k]\n",
    "        # Subtract from current column its' components in preceding.\n",
    "        for j in range(k):  # Columns.\n",
    "            R[j,k] = np.dot(Q[:,j], A[:,k])\n",
    "            Q[:,k] -= R[j,k] * Q[:,j]\n",
    "        R[k,k] = np.linalg.norm(Q[:,k])\n",
    "        if abs(R[k,k]) < np.finfo('d').eps:\n",
    "            break  # Linearly depdendent.\n",
    "        Q[:,k] /= R[k,k]  # Normalize.\n",
    "    return Q[:,:n], R[:n,:]\n",
    "\n",
    "\n",
    "# Input data $(t_i, b_i)$.\n",
    "m = 5\n",
    "t = np.linspace(-1., 1., m)\n",
    "b = np.array([1., 0.5, 0., 0.5, 2.]).reshape(m, 1)\n",
    "A = np.column_stack((np.ones(m), t, t*t))\n",
    "n = A.shape[1]\n",
    "\n",
    "# Factorize A into QR.\n",
    "Q, R = cgs_qr(A)\n",
    "np.testing.assert_almost_equal(A, np.matmul(Q, R))  # Self-check.\n",
    "\n",
    "# Apply the Gram-Schmidt transformation to b.\n",
    "c = np.matmul(Q.T, b)\n",
    "\n",
    "# Solve Rx = c for x by back substitution.\n",
    "# NOTE(mmorais): Both R and c must be square.\n",
    "x = la.solve_triangular(R, c[:n], lower=False, unit_diagonal=False)\n",
    "\n",
    "# Compute the squared 2-norm of the residual.\n",
    "resid = y - np.matmul(A, x)\n",
    "sq2norm = np.linalg.norm(resid, ord=2)**2\n",
    "\n",
    "# Compare to the residual returned from np.linalg.lstsq.\n",
    "_, r, _, _ = np.linalg.lstsq(A, b, rcond=None)\n",
    "np.testing.assert_almost_equal(sq2norm, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve $Ax = b$ for $x$ where $A$ is $m \\times n$ using modified Gram-Schmidt QR factorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "\n",
    "def mgs_qr(A):\n",
    "    \"\"\"\n",
    "    Use modified Gram-Schmidt to factorize A into QR.\n",
    "\n",
    "    Returns orthogonal matrix Q and upper right triangular matrix R.\n",
    "    \"\"\"\n",
    "    m, n = A.shape\n",
    "    Q, R, AA = np.eye(m), np.zeros((m, n)), np.copy(A)\n",
    "    for k in range(n):  # Columns.\n",
    "        R[k,k] = np.linalg.norm(AA[:,k])\n",
    "        if abs(R[k,k]) < np.finfo('d').eps:\n",
    "            break  # Linearly depdendent.\n",
    "        Q[:,k] = AA[:,k] / R[k,k]  # Normalize.\n",
    "        # Subtract from succeeding columns the components in current.\n",
    "        for j in range(k+1,n): # Columns.\n",
    "            R[k,j] = np.dot(Q[:,k], AA[:,j])\n",
    "            AA[:,j] -= R[k,j] * Q[:,k]\n",
    "    return Q[:,:n], R[:n,:]\n",
    "\n",
    "\n",
    "# Input data $(t_i, b_i)$.\n",
    "m = 5\n",
    "t = np.linspace(-1., 1., m)\n",
    "b = np.array([1., 0.5, 0., 0.5, 2.]).reshape(m, 1)\n",
    "A = np.column_stack((np.ones(m), t, t*t))\n",
    "n = A.shape[1]\n",
    "\n",
    "# Factorize A into QR.\n",
    "Q, R = mgs_qr(A)\n",
    "np.testing.assert_almost_equal(A, np.matmul(Q, R))  # Self-check.\n",
    "\n",
    "# Apply the Gram-Schmidt transformation to b.\n",
    "c = np.matmul(Q.T, b)\n",
    "\n",
    "# Solve Rx = c for x by back substitution.\n",
    "# NOTE(mmorais): Both R and c must be square.\n",
    "x = la.solve_triangular(R, c[:n], lower=False, unit_diagonal=False)\n",
    "\n",
    "# Compute the squared 2-norm of the residual.\n",
    "resid = y - np.matmul(A, x)\n",
    "sq2norm = np.linalg.norm(resid, ord=2)**2\n",
    "\n",
    "# Compare to the residual returned from np.linalg.lstsq.\n",
    "_, r, _, _ = np.linalg.lstsq(A, b, rcond=None)\n",
    "np.testing.assert_almost_equal(sq2norm, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.08 Rank Deficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If rank(A) < n, then QR factorization exists, but yields singular upper triangular factor R.\n",
    "\n",
    "#### QR with Column Pivoting\n",
    "Instead of processing columns in natural order, select for reduction at each stage column of remaining unreduced submatrix having maximum Euclidean norm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.09 Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVD of a $m \\times n$ matrix $A$ is given by:\n",
    "$$\n",
    "A = U \\Sigma V^T\n",
    "$$\n",
    "where\n",
    "* $U$ is an $m \\times m$ orthogonal matrix\n",
    "  * Columns of $U$ referred to as **left singular vectors**\n",
    "* $\\Sigma$ is an $m \\times n$ diagonal matrix\n",
    "  * Diagonal entries $\\sigma_i$ referred to as **singular values** of $A$\n",
    "  * Typically decreasing order $\\sigma_1 \\geq \\sigma_2 \\geq \\sigma_3 \\cdots \\sigma_n$\n",
    "* $V$ is an $n \\times n$ orthogonal matrix\n",
    "  * Columns of $V$ referred to as **right singular vectors**\n",
    "\n",
    "#### Applications\n",
    "* Minimum norm solution to $Ax \\approxeq b$\n",
    "$$\n",
    "x = \\sum_{\\sigma_i \\neq 0} \\frac{u_i^T b}{\\sigma_i} b\n",
    "$$\n",
    "* Euclidean matrix norm\n",
    "$$\n",
    "||A||_2 = \\sigma_{\\text{max}}\n",
    "$$\n",
    "* Euclidean condition number\n",
    "$$\n",
    "\\text{cond}_2(A) = \\frac{\\sigma_{\\text{max}}}{\\sigma_{\\text{min}}}\n",
    "$$\n",
    "* Rank of matrix = number of nonzero singular values\n",
    "\n",
    "#### Pseudoinverse\n",
    "The pseudoinverse $A^+$ of a $m \\times n$ matrix $A$ is given by:\n",
    "$$\n",
    "A^+ = V \\Sigma^+ U^T\n",
    "$$\n",
    "where\n",
    "* $\\Sigma^+$ is a diagonal matrix with reciprocal and transpose of singular values.\n",
    "* $A^+$ always exists, even when matrix is not full rank.\n",
    "* If $A$ is square and nonsingular, then $A^+ = A^{-1}$\n",
    "* Minimum norm solution to $Ax \\approxeq b$ given by $x = A^+ b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Least Squares\n",
    "Ordinary least squares (OLS) is applicable when $b$ is subject to random error but $A$ is known accurately.\n",
    "\n",
    "Total least squares (TLS) is applicable when $b$ and $A$ are subject to random error.\n",
    "* Unlike OLS, we minimize orthogonal distances rather than vertical distances.\n",
    "* TLS is computed from SVD of $[A | b]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decompose A into $U$, $\\Sigma$, and $V$ using numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes U: (4, 4)  S: (3,)  V^T: (3, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.arange(1, 13).reshape(4,3)\n",
    "\n",
    "# Factorize A into SVD.\n",
    "U, Sigma, VT = np.linalg.svd(A)\n",
    "print(\"shapes U:\", U.shape, \" S:\", Sigma.shape, \" V^T:\", VT.shape)\n",
    "\n",
    "# Reconstruct A from factorization.\n",
    "np.testing.assert_almost_equal(A, \n",
    "    np.matmul(U[:,:Sigma.shape[0]] * Sigma, VT))\n",
    "\n",
    "# Compare sigma_max to Euclidean norm.\n",
    "np.testing.assert_almost_equal(np.linalg.norm(A, ord=2), np.max(Sigma))\n",
    "\n",
    "# Compare sigma_max / sigma_min to Euclidean condition number.\n",
    "np.testing.assert_allclose(np.linalg.cond(A, p=2), \n",
    "                           np.max(Sigma)/np.min(Sigma))\n",
    "\n",
    "# Compare number of nonsingular values to rank.\n",
    "# NOTE: Comparing against eps insufficient, need larger tolerance.\n",
    "np.testing.assert_equal(np.linalg.matrix_rank(A), \n",
    "                        np.where(Sigma > 1e-14)[0].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve $Ax = b$ for $x$ where $A$ is $m \\times n$ using SVD factorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes U: (5, 5)  S: (3,)  V^T: (3, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Input data $(t_i, b_i)$.\n",
    "m = 5\n",
    "t = np.linspace(-1., 1., m)\n",
    "b = np.array([1., 0.5, 0., 0.5, 2.]).reshape(m, 1)\n",
    "A = np.column_stack((np.ones(m), t, t*t))\n",
    "n = A.shape[1]\n",
    "\n",
    "# Factorize A into SVD.\n",
    "U, Sigma, VT = np.linalg.svd(A)\n",
    "print(\"shapes U:\", U.shape, \" S:\", Sigma.shape, \" V^T:\", VT.shape)\n",
    "\n",
    "# Compute \\Sigma^+ by taking reciprocal of singular values.\n",
    "Sigmaplus = np.diag(1./Sigma).T\n",
    "\n",
    "# Compute the pseudoinverse A^+ = V \\Sigma^+ U^T.\n",
    "Aplus = np.matmul(np.matmul(VT.T, Sigmaplus), U[:,:Sigma.shape[0]].T)\n",
    "\n",
    "# Solve for x using x = A^+ b.\n",
    "x = np.matmul(Aplus, b)\n",
    "\n",
    "# Compute the squared 2-norm of the residual.\n",
    "resid = y - np.matmul(A, x)\n",
    "sq2norm = np.linalg.norm(resid, ord=2)**2\n",
    "\n",
    "# Compare to the residual returned from np.linalg.lstsq.\n",
    "_, r, _, _ = np.linalg.lstsq(A, b, rcond=None)\n",
    "np.testing.assert_almost_equal(sq2norm, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.10 Comparison of Methods for Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Method | Complexity | Notes |\n",
    "|--------|------------|-------|\n",
    "| normal equations | $n^3/6$ | unstable |\n",
    "| Householder QR | $n^3/3$ | stable |\n",
    "| SVD | $n^3$ | robust, but expensive |\n",
    "\n",
    "Comparing relative error of solutions by method.\n",
    "* Normal equations method breaks down when condition number is $> 1/\\sqrt{\\epsilon_{\\text{mach}}}$.\n",
    "$$\n",
    "\\text{rel. error} = [\\text{cond}(A)]^2\n",
    "$$\n",
    "* Householder method is best possible esp. when residual is small.\n",
    "$$\n",
    "\\text{rel. error} = \\text{cond}(A) + ||r||_2 [\\text{cond}(A)]^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
