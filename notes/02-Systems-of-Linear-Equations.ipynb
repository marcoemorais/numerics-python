{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Systems of Linear Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.01 Systems of Linear Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix-Vector Product\n",
    "\n",
    "Think of $Ax=b$ as linear combination of the columns of A.\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "Ax &=\n",
    "\\begin{bmatrix}\n",
    "a_{1,1} & a_{1,2} & \\cdots & a_{1,n} \\\\\n",
    "a_{2,1} & a_{2,2} & \\cdots & a_{2,n} \\\\\n",
    "\\vdots & \\vdots &  & \\vdots \\\\\n",
    "a_{m,1} & a_{m,2} & \\cdots & a_{m,n} \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "\\vdots \\\\\n",
    "x_n \\\\\n",
    "\\end{bmatrix} \\\\\n",
    "&= \n",
    "x_1\n",
    "\\begin{bmatrix}\n",
    "a_{1,1} \\\\\n",
    "\\vdots \\\\\n",
    "a_{m,1} \\\\\n",
    "\\end{bmatrix}\n",
    "+\n",
    "x_2\n",
    "\\begin{bmatrix}\n",
    "a_{1,2} \\\\\n",
    "\\vdots \\\\\n",
    "a_{m,2} \\\\\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\cdots\n",
    "+\n",
    "x_n\n",
    "\\begin{bmatrix}\n",
    "a_{1,n} \\\\\n",
    "\\vdots \\\\\n",
    "a_{m,n} \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "The following terms are equivalent:\n",
    "* span\n",
    "* column space\n",
    "* range\n",
    "\n",
    "**Def** For $A \\in \\mathbb{R}^{m \\times n}$, $\\text{span}(A) = \\{ Ax : x \\in \\mathbb{R}^n \\}$.\n",
    "* Span of a matrix is the set of all possible linear combinations.\n",
    "\n",
    "Solving a linear system $Ax =b$ is really asking the question: Is $b \\in \\text{span}(A)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Singularity\n",
    "\n",
    "A matrix is **nonsingular** when:\n",
    "1. There exists $A^{-1}$ such that $AA^{-1} = A^{-1}A = I$\n",
    "2. $\\text{det}(A) \\neq 0$\n",
    "3. $\\text{rank}(A) = n$\n",
    "4. For any vector $z \\neq 0$, then $Az \\neq 0$.\n",
    "\n",
    "#### Uniqueness\n",
    "\n",
    "When A is **nonsingular**, then b must be unique.\n",
    "* Geometric interpretation: b is the intersection of the hyperplanes formed by the intersections of each of the equations that form A.\n",
    "\n",
    "| A | b | # solutions |\n",
    "| :-: | :-: | :-----------: |\n",
    "| nonsingular | arbitrary | 1 |\n",
    "| singular | system consistent eg $b \\in \\text{span}(A)$ | $\\infty$ |\n",
    "| singular | system not consistent eg $b \\notin \\text{span}(A)$ | 0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate that when $A$ is nonsingular, a unique solution exists for every abritrary $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[2, 3],[5, 4]])\n",
    "assert(np.linalg.det(A) != 0.)  # A is nonsingular.\n",
    "\n",
    "# Since A is nonsingular, solution exists for arbitrary b.\n",
    "b = np.random.random(2)\n",
    "x = np.linalg.solve(A, b)\n",
    "np.testing.assert_almost_equal(np.matmul(A, x), b)  # Definition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate that when $A$ is singular, no solution exists for arbitrary $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected:  Singular matrix\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[2, 3],[4, 6]])\n",
    "assert(np.linalg.det(A) == 0.)  # A is singular.\n",
    "\n",
    "# Since A is singular, there is no **unique** solution.\n",
    "# NOTE: numpy returns error when there are infinite solutions.\n",
    "b = np.random.random(2)\n",
    "try:\n",
    "    x = np.linalg.solve(A, b)\n",
    "except np.linalg.LinAlgError as ex:\n",
    "    print(\"expected: \", ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.02 Norms and Condition Number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vector Norms\n",
    "\n",
    "The notion of **magnitude** generalizes to **norm** for vectors.\n",
    "$$\n",
    "||x||_p = \\left( \\sum_{i=1}^{n} |x_i|^p \\right)^{1/p}\n",
    "$$\n",
    "\n",
    "In general, for any vector $x \\in \\mathbb{R}$, then $ ||x||_1 \\leq ||x||_2 \\leq ||x||_{\\infty}$.\n",
    "\n",
    "Properties\n",
    "* Triange inequality $||x + y|| \\leq ||x|| + ||y||$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate p-norms with numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-norm:    2.8\n",
      "2-norm:    2.0\n",
      "inf-norm:  1.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Demonstrate computation of p-norm for same vector.\n",
    "x = np.array([-1.6, 1.2])\n",
    "print(\"1-norm:   \", np.linalg.norm(x, ord=1))\n",
    "print(\"2-norm:   \", np.linalg.norm(x, ord=2))\n",
    "print(\"inf-norm: \", np.linalg.norm(x, ord=np.inf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix Norms\n",
    "\n",
    "The notion of norms extends to matrices.\n",
    "\n",
    "$$\n",
    "||A|| = \\text{max}_{x \\neq 0} \\frac{||Ax||}{||x||}\n",
    "$$\n",
    "\n",
    "* Note that $Ax$ is a vector, thus $||Ax||$ will be a vector norm.\n",
    "* The ratio of $\\frac{||Ax||}{||x||}$ measures the amount of stretching that matrix $A$ applies to the vector $x$ from $A$.\n",
    "\n",
    "The simplest matrix norm to compute is the 1-norm which is the maximum absolute column sum of a $m \\times n$ matrix.\n",
    "\n",
    "$$\n",
    "||A||_1 = \\max_{j} \\sum_{i=1}^{m} |a_{ij}|\n",
    "$$\n",
    "\n",
    "Properties\n",
    "* $||AB|| \\leq ||A|| \\cdot ||B||$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condition Number\n",
    "\n",
    "Matrix norms are used to define condition number.\n",
    "\n",
    "$$\n",
    "\\text{cond}(A) = ||A|| \\cdot ||A^{-1}||\n",
    "$$\n",
    "\n",
    "* Larger values of $\\text{cond}(A)$ imply closer to singularity.\n",
    "* Conceptually, the more stretching that matrix $A$ applies, then the larger the condition number and closer to singular.\n",
    "\n",
    "Properties\n",
    "* For any matrix $A$, then $\\text{cond}(A) \\geq 1$.\n",
    "* For identity matrix $I$, then $\\text{cond}(I) = 1$.\n",
    "* For any matrix $A$ and scalar $\\gamma$, then $\\text{cond}(\\gamma A) = \\text{cond}(A)$\n",
    "* For any diagonal matrix $D$, then $\\text{cond}(D) = \\frac{\\text{max}|d_i|}{\\text{min}|d_i|}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate condition number with numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "p = 2  # Use 2-norm as example.\n",
    "\n",
    "A = np.array([[2, -1, 1],[1, 0, 1],[3, -1, 4]])\n",
    "Ainv = np.linalg.inv(A)\n",
    "\n",
    "# Compute the norm of each matrix.\n",
    "normA = np.linalg.norm(A, ord=p)\n",
    "normAinv = np.linalg.norm(Ainv, ord=p)\n",
    "\n",
    "# Compute the condition number from norm and compare.\n",
    "condA = normA * normAinv\n",
    "np.testing.assert_almost_equal(condA, np.linalg.cond(A, p=p))\n",
    "\n",
    "# Compute the condition number of diagonal matrix and compare.\n",
    "D = np.diag(np.arange(1, 10))\n",
    "condD = np.max(np.diag(D)) / np.min(np.diag(D))\n",
    "np.testing.assert_almost_equal(condD, np.linalg.cond(D, p=p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.03 Assessing Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error Bounds\n",
    "\n",
    "Let $x$ be solution to $Ax = b$ and $\\hat{x}$ be solution to $A\\hat{x} = b + \\Delta{b}$.\n",
    "\n",
    "Use $\\Delta{x} = \\hat{x} - x$ to bound the change in $x$ to the change in $b$.\n",
    "\n",
    "$$\n",
    "\\frac{||\\Delta{x}||}{||x||} \\leq \\text{cond}(A)\\frac{||\\Delta{b}||}{||b||}\n",
    "$$\n",
    "\n",
    "The product of the condition number of the matrix and machine epsilon provide an upper bound on the relative error in the approximate solution. \n",
    "\n",
    "$$\n",
    "\\frac{||\\hat{x} - x||}{||x||} \\leq \\text{cond}(A) \\epsilon_{mach}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residual\n",
    "\n",
    "Residual vector $r$ of approximate solution $\\hat{x}$ to $Ax=b$.\n",
    "\n",
    "$$\n",
    "r = b - A \\hat{x}\n",
    "$$\n",
    "\n",
    "* Useful as measure of error when $\\text{cond}(A)$ is small.\n",
    "* A small residual does not necessarily imply solution is accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate example where small residual and ill-conditioned matrix does not imply an accurate solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condA:  12485.031415973846\n",
      "norm1:  0.000206163090780105\n",
      "norm2:  0.0017579968714420229\n",
      "deltax:  1.8499295364961637\n",
      "deltax:  0.0014142135623337656\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Consider an example with an ill-conditioned matrix A.\n",
    "A = np.array([[0.913, 0.659],[0.457, 0.330]])\n",
    "b = np.array([0.254, 0.127]).reshape(2, 1)\n",
    "\n",
    "print(\"condA: \", np.linalg.cond(A))\n",
    "\n",
    "# Consider two approximate solutions.\n",
    "xhat1 = np.array([-0.0827, 0.5]).reshape(2, 1)\n",
    "xhat2 = np.array([0.999, -1.001]).reshape(2, 1)\n",
    "\n",
    "# Compute the residual for each.\n",
    "resid1 = b - np.matmul(A, xhat1)\n",
    "resid2 = b - np.matmul(A, xhat2)\n",
    "\n",
    "# Since norm(resid1) < norm(resid2), \n",
    "# then we might think that xhat1 is better than xhat2.\n",
    "print(\"norm1: \", np.linalg.norm(resid1, ord=2))\n",
    "print(\"norm2: \", np.linalg.norm(resid2, ord=2))\n",
    "\n",
    "# True solution is [1, -1]^T and xhat2 is a better approximation.\n",
    "x = np.linalg.solve(A, b)\n",
    "print(\"deltax: \", np.linalg.norm(xhat1 - x, ord=2))\n",
    "print(\"deltax: \", np.linalg.norm(xhat2 - x, ord=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.04 Solving Linear Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General Approach** Replace a difficult problem by an easier one having the same or closely related solution.\n",
    "\n",
    "#### Linear Systems\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Ax &= b \\\\\n",
    "MAx &= Mb \\\\\n",
    "x &= (MA)^{-1}Mb \\\\\n",
    "x &= A^{-1} M^{-1} Mb \\\\\n",
    "x &= A^{-1} Ib \\\\\n",
    "x &= A^{-1}b\n",
    "\\end{aligned}\n",
    "$$\n",
    "* Solution: Premultiply each side of $Ax = b$ by nonsingular matrix $M$.\n",
    "\n",
    "#### Permutations\n",
    "Let $P$ be the permutation matrix.\n",
    "* $P$ is an identity matrix with rows or columns permuted such that each row and column has exactly one cell with value of `1` and all other cells are `0`.\n",
    "* $PAx = Pb$ reorders rows, but solution $x$ unchanged.\n",
    "* $P^T = P^{-1}$ reverses permutation. \n",
    "\n",
    "#### Diagonal Scaling\n",
    "Let $D$ be a diagnonal matrix.\n",
    "* $DAx = Db$ multiplies each row by corresponding entry of $D$, but solution $x$ is unchanged.\n",
    "\n",
    "#### Triangular \n",
    "Let $U$ be an upper triangular system and $L$ be a lower triangular system.\n",
    "* $U$ can be solved by back substitution.\n",
    "$$\n",
    "x_i = \\frac{\\left( b_i - \\sum_{j=i+1}^{n} U_{ij}x_j \\right)}{U_{ii}} \\qquad i=n-1,\\cdots,1\n",
    "$$\n",
    "* $L$ can be solved by forward substitution.\n",
    "$$\n",
    "x_i = \\frac{\\left( b_i - \\sum_{j=1}^{i-1} L_{ij}x_j \\right)}{L_{ii}} \\qquad i=1,\\cdots,n\n",
    "$$\n",
    "* Any system can be permuted into $L$ or $U$ using $P$ and $D$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate back substitution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def backsubstitution(U, b):\n",
    "    \"\"\"\n",
    "    Perform backsubstitution to solve [U|b] for x.\n",
    "    \"\"\"\n",
    "    x = np.zeros((U.shape[1], b.shape[1]))\n",
    "\n",
    "    for i in range(U.shape[0]-1, -1, -1):\n",
    "        x[i] = (b[i] - np.sum(np.dot(U[i,i+1:], x[i+1:]))) / U[i,i]\n",
    "    \n",
    "    return x\n",
    "\n",
    "# Solve Ux = b for x.\n",
    "U = np.array([[2,4,-2],[0,1,1],[0,0,4]])\n",
    "b = np.array([2,4,8]).reshape(3,1)\n",
    "x = backsubstitution(U, b)\n",
    "np.testing.assert_almost_equal(x, np.array([-1,2,2]).reshape(3,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate forward substitution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def forwardsubstitution(L, b):\n",
    "    \"\"\"\n",
    "    Perform forward substitution to solve [L|b] for x.\n",
    "    \"\"\"\n",
    "    x = np.zeros((L.shape[1], b.shape[1]))\n",
    "    \n",
    "    for i in range(U.shape[0]):\n",
    "        x[i] = (b[i] - np.sum(np.dot(L[i,:i], x[:i]))) / L[i,i]\n",
    "\n",
    "    return x\n",
    "\n",
    "# Solve Lx = b for x.\n",
    "L = np.array([[2,0,0],[-1,2,0],[1,-1,1]])\n",
    "b = np.array([28,-40,33]).reshape(3,1)\n",
    "x = forwardsubstitution(L, b)\n",
    "np.testing.assert_almost_equal(x, np.array([14,-13,6]).reshape(3,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.05 Elementary Elimination Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devise a nonsingular **linear transformation** that transforms linear system $Ax = b$ to a triangular system that we solve via substitution.\n",
    "\n",
    "In general any row can be eliminated by adding a multiple $m_i = \\frac{-a_i}{a_k}, i=k+1,\\cdots,n$ where $a_k$ is reffered to as the **pivot**.\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "\\frac{-a_2}{a_1} & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "a_1 \\\\\n",
    "a_2 \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "a_1 \\\\\n",
    "0 \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.06 LU Factorization by Gaussian Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Elimination\n",
    "Gaussian elimination transforms the systems of equations described by $Ax = b$ to an equivalent system described by $Ux = c$ where $U$ is an upper triangular matrix.\n",
    "\n",
    "Solve.\n",
    "* Solve $Ux = c$ for $x$ by back substitution.\n",
    "\n",
    "#### LU Factorization\n",
    "LU factorization transforms the systems of equations described by $Ax = b$ to an equivalent system described by $LUx = b$ where $L$ is a lower triangular matrix and $U$ is an upper triangular matrix.\n",
    "\n",
    "Solve.\n",
    "* Solve $Ly = b$ for $y$ by forward substitution.\n",
    "* Solve $Ux = y$ for $x$ by back substitution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate Gaussian elimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gaussian_elimination(A, b):\n",
    "    \"\"\"\n",
    "    Use gaussian elimination to transform [A|b] to [U|c].\n",
    "    \"\"\"\n",
    "    for k in range(A.shape[1]):  # Columns.\n",
    "        for i in range(k+1, A.shape[0]):  # Rows.\n",
    "            m_i = -1.0 * A[i,k] / A[k,k]\n",
    "            A[i,:] += m_i * A[k,:]\n",
    "            b[i,:] += m_i * b[k,:]\n",
    "\n",
    "    return A, b\n",
    "\n",
    "# Transform Ab to Uc.\n",
    "A = np.array([[1,2,2],[4,4,2],[4,6,4]], dtype='d')\n",
    "b = np.array([3,6,10], dtype='d').reshape(3,1)\n",
    "A, b = gaussian_elimination(A, b)\n",
    "np.testing.assert_almost_equal(A, np.array([[1,2,2],[0,-4,-6],[0,0,-1]]))\n",
    "np.testing.assert_almost_equal(b, np.array([3,-6,1]).reshape(3,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate LU factorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def lu_factorization(A):\n",
    "    \"\"\"\n",
    "    Use LU factorization to transform [A] to [L|U].\n",
    "    \"\"\"\n",
    "    for k in range(A.shape[1]):  # Columns.\n",
    "        for i in range(k+1, A.shape[0]):  # Rows.\n",
    "            A[i,k] = A[i,k] / A[k,k]\n",
    "            A[i,k+1:] += -1.0 * A[i,k] * A[k,k+1:]\n",
    "    return A\n",
    "\n",
    "# Transform A to LU.\n",
    "A = np.array([[1,2,2],[4,4,2],[4,6,4]], dtype='d')\n",
    "LU = lu_factorization(A)\n",
    "np.testing.assert_almost_equal(LU, np.array([[1,2,2],[4,-4,-6],[4,0.5,-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate solving $Ax = b$ using LU factorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a random square matrix A and x.\n",
    "A = np.random.random((3, 3))\n",
    "x = np.random.random((3, 1))\n",
    "b = np.matmul(A, x)\n",
    "\n",
    "# Factorize A.\n",
    "LU = lu_factorization(A)\n",
    "\n",
    "# Solve Ly=b for y.\n",
    "L = np.tril(LU)\n",
    "# Diagonal holds elements of U, replace with 1.0.\n",
    "np.fill_diagonal(L, 1.0)\n",
    "y = forwardsubstitution(L, b)\n",
    "\n",
    "# Solve Ux=y for x.\n",
    "U = np.triu(LU)\n",
    "xhat = backsubstitution(U, y)\n",
    "\n",
    "np.testing.assert_almost_equal(xhat, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.07 Pivoting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian elimination breaks down if the leading diagonal entry of the remaining unreduced matrix is `0` or near `0`.\n",
    "\n",
    "**row pivoting** If the value of the leading diagonal entry in the pivot row is `0` or near `0`, then interchange that row with some other row having a nonzero entry.\n",
    "* Any nonzero value will suffice as pivot, but in order to reduce the effect of rounding errors, the largest such value is chosen.  This is known as **partial pivoting**.\n",
    "\n",
    "Gaussian elimination without pivoting is **unstable**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate LU factorization with partial pivoting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def lu_factorization_pp(A):\n",
    "    \"\"\"\n",
    "    Use LU factorization with partial pivoting to transform [A] to [L|U].\n",
    "    \"\"\"\n",
    "    # p contains the row interchanges to apply to b.\n",
    "    p = np.arange(A.shape[0])\n",
    "    for k in range(A.shape[1]):  # Columns.\n",
    "        # Interchange pivot and row with maximum value in column k.\n",
    "        maxrow = k + np.argmax(np.abs(A[k:,k]))\n",
    "        # NOTE(mmorais): Special slicing syntax to swap copies.\n",
    "        A[[k, maxrow],:] = A[[maxrow, k],:]\n",
    "        p[[k, maxrow]] = p[[maxrow, k]]\n",
    "        for i in range(k+1, A.shape[0]):  # Rows.\n",
    "            A[i,k] = A[i,k] / A[k,k]\n",
    "            A[i,k+1:] += -1.0 * A[i,k] * A[k,k+1:]\n",
    "    return A, p\n",
    "\n",
    "def lu_solve(LU, p, b):\n",
    "    \"\"\"\n",
    "    Solve LUx = b for x.\n",
    "    \"\"\"\n",
    "    # Solve Ly=b for y.\n",
    "    L = np.tril(LU)\n",
    "    # Diagonal holds elements of U, replace with 1.0.\n",
    "    np.fill_diagonal(L, 1.0)\n",
    "    # Reorder b according to the row interchanges p.\n",
    "    y = forwardsubstitution(L, b[p, np.newaxis])\n",
    "    \n",
    "    # Solve Ux=y for x.\n",
    "    U = np.triu(LU)\n",
    "    x = backsubstitution(U, y)\n",
    "    \n",
    "    return x\n",
    "    \n",
    "# Transform A to LU.\n",
    "A = np.array([[2,-2,6],[-2,4,3],[-1,8,4]], dtype='d')\n",
    "x = np.array([1,2,-1], dtype='d').reshape(3,1)\n",
    "b = np.matmul(A, x)\n",
    "LU, p = lu_factorization_pp(A)\n",
    "xhat = lu_solve(LU, p, b)\n",
    "\n",
    "np.testing.assert_almost_equal(xhat, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.08 Residual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian elimination with partial pivoting is guaranteed to provide a small residual.\n",
    "* Bound on the residual given by:\n",
    "$$\n",
    "\\frac{||E||}{||A||} \\leq n \\epsilon_{\\text{mach}}\n",
    "$$\n",
    "\n",
    "where\n",
    "* $||E||$ is the backward error in matrix $A$.\n",
    "* $||A||$ is the matrix norm.\n",
    "* $n$ is the dimension of $A$.\n",
    "\n",
    "As described earlier, a small residual and ill-conditioned matrix does not imply an accurate solution.\n",
    "* If the condition number of the matrix $\\text{cond}(A)$ is high, then the system is ill-conditioned and the solution is not accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.09 Implementing Gaussian Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerations for LU factorization with partial pivoting:\n",
    "* Both $L$ and $U$ replace the contents of $A$.\n",
    "  * The upper triangular elements of $A$ (including diagonal) are replaced with $U$.\n",
    "  * The lower triangular elements of $A$ (excluding diagonal) are replaced with $L$.\n",
    "* An auxiliary vector $P$ stores the row interchanges.\n",
    "\n",
    "Inversion vs. Factorization\n",
    "* LU factorization requires $n^3/3$ floating point multiplications and additions.\n",
    "* Solving the system by explicitly computing the inverse $x = A^{-1}b$ requires $n^3$ floating point multiplications and additions.\n",
    "  * The computational cost of computing inverse is 3x larger than LU factorization.\n",
    "  * In practice, computing the inverse is rarely done.\n",
    "  \n",
    "Gauss-Jordan elimination is sometimes used to solve a linear system.\n",
    "  * Transforms $Ax = b$ to $Ix = c$.\n",
    "  * Solving system with Gauss-Jordan rquires $n^3/2$ floating point multiplications and additions.\n",
    "  * Gauss-Jordan elimination is less often used due to increased computational cost in comparison to LU factorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.10 Updating Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a right-hand side of a linear system $b$ changes, but the matrix $A$ does not then the LU factorization can be reused.\n",
    "\n",
    "**Sherman-Morrison** formula describes a situation when refactorization can be avoided when matrix changes.\n",
    "* Assume $(A - uv^T)$ represents the modification to $A$.\n",
    "* Solution becomes $x = (A - uv^T)^{-1}b$.\n",
    "\n",
    "Solve using Sherman-Morrison as follows:\n",
    "1. Solve $Az = u$ for $z$.\n",
    "2. Solve $Ay = b$ for $y$.\n",
    "3. Compute $x = y + z \\frac{v^T y}{1 - v^T z}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.11 Improving Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling Linear Systems\n",
    "It is usually best from perspective of stability if all entries of the matrix have the same magnitude.\n",
    "* No foolproof method, use trial-and-error.\n",
    "\n",
    "#### Iterative Refinement\n",
    "Given a linear system $Ax = b$, solve for $x$ using approximation and residual.\n",
    "1. Solve $Ax_0 = b$ for the approximation $x_0$ and compute residual $r_0 = b - Ax_0$.\n",
    "2. Solve $Az_0 = r_0$ for $z_0$ and obtain new solution $x_1 = x_0 + z_0$.\n",
    "3. Repeat until convergence.\n",
    "\n",
    "Rarely used, but can sometimes stabilize an unstable algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.12 Special Types of Linear Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special Systems\n",
    "* Symmetric: $A = A^T$\n",
    "* Positive definite: $x^T A x \\gt 0$ for all $x \\neq 0$\n",
    "* Band: $a_{ij} = 0$ for all $|i - j| \\gt \\beta$\n",
    "* Sparse: most entries of $A$ are zero\n",
    "\n",
    "#### Positive Definite\n",
    "Use **cholesky factorization** to transform $A$ to $LL^T$.\n",
    "* Uses square root of the pivot element.\n",
    "  * No row interchanges are required.\n",
    "* Solving system requires $n^3/6$ floating point multiplications and additions (half the work of LU factorization).\n",
    "\n",
    "#### Band Matrices\n",
    "* Solver for band matrices are similar to Gaussian elimination except rows with zero entries are skipped.\n",
    "* **Tridiagonal matrices** (band matrix with $\\beta = 3$) reduce to $n$ floating point multiplications and additions.\n",
    "\n",
    "#### Iterative Methods\n",
    "* Direct methods produce exact solution in finite number of steps.\n",
    "  * Gaussian elimination is an example of a direct method.\n",
    "* Iterative methods begin with initial guess and improve it until desired accuracy obtained.\n",
    "  * Indirect methods used to solve partial diffferential equations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate cholesky factorization to solve positive definite system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def cholesky_factorization(A):\n",
    "    \"\"\"\n",
    "    Use cholesky factorization to transform [A] to [L|L^T].\n",
    "    \n",
    "    Assume that A is positive definite.\n",
    "    \"\"\"\n",
    "    for k in range(A.shape[1]):  # Columns.\n",
    "        A[k,k] = math.sqrt(A[k,k])\n",
    "        for i in range(k+1,A.shape[0]):  # Rows.\n",
    "            A[i,k] = A[i,k] / A[k,k]\n",
    "            # NOTE: Unlike LU factorization, only L is implicated.\n",
    "            A[i,k+1:] += -1.0 * A[i,k] * A[i,k]\n",
    "    return A\n",
    "    \n",
    "A = np.array([[3,-1,-1],[-1,3,-1],[-1,-1,3]], dtype='d')\n",
    "\n",
    "# Confirm that A is positive definite.\n",
    "x = np.random.random(3).reshape(3,1)\n",
    "pd = np.matmul(np.matmul(x.T, A), x)\n",
    "np.testing.assert_equal(pd > 0, True)\n",
    "\n",
    "LLT = cholesky_factorization(A)\n",
    "\n",
    "expected = np.array([[1.73205081,0.,0.],[-0.57735027,1.63299316,0.],[-0.57735027,-0.81649658,1.41421356]])\n",
    "np.testing.assert_almost_equal(np.tril(LLT), np.tril(expected))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.13 Software Linear Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LINPACK\n",
    "* Historically important, now obsolete.\n",
    "* Used only for supercomputer benchmark.\n",
    "\n",
    "LAPACK\n",
    "* Replaces LINPACK.\n",
    "* Wrapped by MATLAB and NumPy.\n",
    "\n",
    "BLAS\n",
    "* Low-level vector, matrix-vector, and matrix-matrix operations.\n",
    "* LAPACK is implemented using BLAS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Solving linear systems is fundamental.\n",
    "* Sensitivity of linear system measured by $\\text{cond}(A)$.\n",
    "* Triangular systems easily solvable using forward or back substitution.\n",
    "* General linear system solved by transforming to triangular form using Gaussian elimination or LU factorization.\n",
    "* Pivoting essential for stability of Gaussian elimination.\n",
    "* Specialized software such as LAPACK and BLAS available for solving linear systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
