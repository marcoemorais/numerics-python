{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.01 Linear Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem: Measurements Have Error\n",
    "* Measurement errors are inevitable\n",
    "* Variability can be smoothed out by averaging over more data\n",
    "* Resulting system is **overdetermined**\n",
    "  * More equations (rows) than unknowns (columns)\n",
    "\n",
    "#### Solution: Use Least Squares\n",
    "* Project higher dimensional data into lower dimensional space\n",
    "* Suppresses noise and irrelevant detail\n",
    "* Better written as $Ax \\approxeq b$\n",
    "  * Emphasis that $x$ is not exact solution\n",
    "* Solution minimizes squared 2-norm of residual\n",
    "  * $\\min_x ||r||_2^2 = \\min_x || b - Ax ||_2^2$\n",
    "\n",
    "\n",
    "What does *linear* mean?\n",
    "* If $f(t, x)$ is the function represented by $Ax = b$, then coefficients of $A$ are some power of $t$.\n",
    "$$\n",
    "f(t, x) = x_1 + x_2 t + x_3 t^2 + ... + x_n t^{n-1}\n",
    "$$\n",
    "* Non-linear counterexample.\n",
    "$$\n",
    "f(t, x) = x_1 + x_2 e^{t} + x_3 e^{t^2} + ... + x_n e^{t^{n-1}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given $m$ data points $(t_i, y_i)$ find n-vector $x$ of parameters that gives best fit to model function $f(t, x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Input data $(t_i, y_i)$.\n",
    "m = 5\n",
    "t = np.linspace(-1., 1., m)\n",
    "y = np.array([1., 0.5, 0., 0.5, 2.]).reshape(m, 1)\n",
    "\n",
    "# Solve Ax = y for x.\n",
    "A = np.column_stack((np.ones(m), t, t*t))\n",
    "x, r, _, _ = np.linalg.lstsq(A, y, rcond=None)\n",
    "\n",
    "# Compute the squared 2-norm of the residual.\n",
    "resid = y - np.matmul(A, x)\n",
    "sq2norm = np.linalg.norm(resid, ord=2)**2\n",
    "\n",
    "# Compare to the residual returned from np.linalg.lstsq.\n",
    "np.testing.assert_almost_equal(sq2norm, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the observations against the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Fit the model to a dense 1D-grid of points from [-1, 1].\n",
    "fitn = m*20\n",
    "fitx = np.linspace(-1, 1, fitn)\n",
    "fitA = np.column_stack((np.ones(fitn), fitx, fitx*fitx))\n",
    "fity = np.matmul(fitA, x)\n",
    "\n",
    "# Plot the fitted model against observations.\n",
    "plt.scatter(t, y, s=16, c='dodgerblue', label='observations')\n",
    "plt.plot(fitx, fity, c='red', label='fit')\n",
    "plt.title('Observations vs. Fit')\n",
    "plt.ylabel('y')\n",
    "plt.xlabel('t')\n",
    "plt.legend(loc=0)  # Upper left corner.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.02 Existence, Uniqueness, and Conditioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Linear least squares problem $Ax \\approxeq b$ **always** has solution.\n",
    "* Solution unique IFF columns are linearly independent aka $\\text{rank}(A) = n$ where $A$ is $m \\times n$.\n",
    "\n",
    "#### Derivation\n",
    "* To minimize the squared 2-norm of residual we need to find the derivative and set to 0.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "||r||_2^2 &= r^T r \\\\\n",
    "&= (b - Ax)^T (b - Ax) \\\\\n",
    "&= b^T b - 2 x^T A^T b + x^T A^T A x \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "* The gradient of $||r||_2^2$ set equal to 0 is aka **normal equations**.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\nabla(||r||_2^2) &= 0 \\\\\n",
    "2 A^T A x - 2 A^T b &= 0 \\\\\n",
    "A^T A x &= A^T b \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "* Since $A^TA$ is square, we can use the techniques for solving systems of linear equations to solve linear least squares problems.\n",
    "\n",
    "#### Orthogonality\n",
    "* $v_1$ and $v_2$ are othogonal when $v_1^T v_2 = 0$.\n",
    "* Value of $y = Ax$ closest to solution $b$ occurs when residual $r = b - Ax$ is orthogonal to $\\text{span}(A)$.\n",
    "  * Project higher dimensional data $b$ ($m \\times 1$) into lower dimensional space $\\text{span}(A)$ (space spanned by columns $n$).\n",
    "* Angle between $y = Ax$ and $b$ computed as:\n",
    "  * $\\text{cos}(\\theta) = \\frac{||y||_2}{||b||_2}$\n",
    "\n",
    "\n",
    "#### Orthogonal Projectors\n",
    "* $P$ is an orthgonal projector when:\n",
    "  * $P^2 = P$ aka idempotent\n",
    "  * $P^T = P$ aka symmetric\n",
    "* We can decompose any vector $v$ into 2 components:\n",
    "  * Component in $\\text{span}(P)$\n",
    "  * Component in $\\text{span}(P)^{\\perp}$ aka orthogonal to $P$\n",
    "* For least squares $P$ is an orthogonal projector onto $\\text{span}(A)$.\n",
    "  * $P = A (A^T A)^{-1} A^T$\n",
    "\n",
    "#### Pseudoinverse\n",
    "* If $A$ is $m \\times n$ and $\\text{rank}(A) = n$, then pseudoinverse is defined as the inverse of the product of the matrix and its' transpose.\n",
    "  * $A^{+} = (A^T A)^{-1} A^T$\n",
    "* Condition number of $A$ defined using pseudoinverse:\n",
    "  * $\\text{cond}(A) = ||A||_2 \\cdot ||A^{+}||_2$\n",
    "* The angle between $y = Ax$ and $b$ also bounds the relative error:\n",
    "  * $\\frac{||\\Delta{x}||}{||x||} \\leq \\text{cond}(A) \\frac{1}{\\text{cos}(\\theta)} \\frac{||\\Delta{b}||}{||b||}$\n",
    "  * When the angle $\\theta$ is small, then $\\theta \\approxeq 0$ and value of $\\text{cos}(\\theta) \\approxeq 1$.  As a result, relative error will be small.\n",
    "  * When the angle $\\theta$ is big, then relative error will be large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.03 Solving Linear Least Squares Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal Equations Method\n",
    "* If $A$ has rank $n$ then symmetric matrix $A^TA$ is positive definite.\n",
    "* Use cholesky factorization solve $Ax = b$ for $x$.\n",
    "  1. Premultiply both sides by $A^T$ to obtain $A^T A x = A^T b$.\n",
    "  2. Factorize $A^T A$ into $L L^T$ to obtain $L L^T x = A^T b$.\n",
    "  3. Solve $L z = A^Tb$ for $z$ using forward substitution.\n",
    "  4. Solve $L^T x = z$ for $x$ using back substitution.\n",
    "* This technique has problems in finite precision arithmetic.\n",
    "  * Computing $A^TA$ introduces roundoff.\n",
    "  * Sensitivity of solution is worsened.\n",
    "    * $\\text{cond}(A^T A) = [\\text{cond}(A)]^2$\n",
    "  * Normal equations method is **unstable** due to these introduced computational errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve $Ax = b$ for $x$ where $A$ is $m \\times n$ using cholesky factorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "\n",
    "# Input data $(t_i, b_i)$.\n",
    "m = 5\n",
    "t = np.linspace(-1., 1., m)\n",
    "b = np.array([1., 0.5, 0., 0.5, 2.]).reshape(m, 1)\n",
    "A = np.column_stack((np.ones(m), t, t*t))\n",
    "\n",
    "# Premultiply the left and right hand side by A^T.\n",
    "ATA = np.matmul(A.T, A)\n",
    "ATb = np.matmul(A.T, b)\n",
    "\n",
    "# Factorize A^T A into L L^T.\n",
    "LLT = np.linalg.cholesky(ATA)\n",
    "\n",
    "# Solve Lz = A^Tb for z using forward substitution.\n",
    "z = la.solve_triangular(LLT, ATb, lower=True, unit_diagonal=False)\n",
    "\n",
    "# Solve L^Tx = z for x using back substitution.\n",
    "x = la.solve_triangular(LLT.T, z, lower=False, unit_diagonal=False)\n",
    "\n",
    "# Compute the squared 2-norm of the residual.\n",
    "resid = y - np.matmul(A, x)\n",
    "sq2norm = np.linalg.norm(resid, ord=2)**2\n",
    "\n",
    "# Compare to the residual returned from np.linalg.lstsq.\n",
    "_, r, _, _ = np.linalg.lstsq(A, b, rcond=None)\n",
    "np.testing.assert_almost_equal(sq2norm, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.04 Orthogonalization Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Matrix $Q$ is orthogonal if $Q^T Q = I$.\n",
    "* Columns of orthogonal matrix are orthonormal eg orthogonal unit vectors.\n",
    "* Multiplying vector by orthogonal matrix does not change its' 2-norm.\n",
    "  * $||Qv||_2^2 = ||v||_2^2$\n",
    "* Use orthogonalization method to solve $Ax = b$ for $x$.\n",
    "  * More computationally expensive than elimination.\n",
    "  * More numerically stable than normal equations method.\n",
    "  \n",
    "#### QR Factorization\n",
    "Given $m \\times n$ matrix $A$ find an $m \\times m$ matrix $Q$.\n",
    "$$\n",
    "A = Q\n",
    "\\begin{bmatrix}\n",
    "R \\\\\n",
    "0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "where\n",
    "  * Q is an $m \\times m$ orthogonal matrix\n",
    "  * R is an $n \\times n$ upper triangular matrix\n",
    "  * 0 is an $(m-n) \\times n$ zero matrix\n",
    "\n",
    "To compute QR factorization of $A$ use one of orthogonal transformations below.\n",
    "  * Householder transformations\n",
    "  * Givens rotations\n",
    "  * Gram-Schmidt orthogonalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve $Ax = b$ for $x$ where $A$ is $m \\times n$ using QR factorization via scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "\n",
    "# Input data $(t_i, b_i)$.\n",
    "m = 5\n",
    "t = np.linspace(-1., 1., m)\n",
    "b = np.array([1., 0.5, 0., 0.5, 2.]).reshape(m, 1)\n",
    "A = np.column_stack((np.ones(m), t, t*t))\n",
    "n = A.shape[1]\n",
    "\n",
    "# Factorize A into QR.\n",
    "Q, R = np.linalg.qr(A)\n",
    "\n",
    "# Apply the same transformations to b.\n",
    "c = np.matmul(Q.T, b)\n",
    "\n",
    "# Solve Rx = c for x by back substitution.\n",
    "# NOTE(mmorais): Both R and c must be square.\n",
    "x = la.solve_triangular(R[:n,:], c[:n], lower=False, unit_diagonal=False)\n",
    "\n",
    "# Compute the squared 2-norm of the residual.\n",
    "resid = y - np.matmul(A, x)\n",
    "sq2norm = np.linalg.norm(resid, ord=2)**2\n",
    "\n",
    "# Compare to the residual returned from np.linalg.lstsq.\n",
    "_, r, _, _ = np.linalg.lstsq(A, b, rcond=None)\n",
    "np.testing.assert_almost_equal(sq2norm, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.05 Householder QR Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Householder reflection (or Householder transformation) is a transformation that takes a vector and reflects it about some plane or hyperplane.\n",
    "  * In the context of linear least squares, the reflection is used to project the vector b into the span(A).\n",
    "\n",
    "Householder transformation of the vector $v$\n",
    "$$\n",
    "H = I - 2 \\frac{v v^T}{v^T v}\n",
    "$$\n",
    "where\n",
    "* H is orthogonal ($H^T H = I$) and symmetric ($H^T = H$)\n",
    "\n",
    "Given some vector $a$ choose $v$ as:\n",
    "$$\n",
    "v = a - \\alpha e_1\n",
    "$$\n",
    "where\n",
    "* $\\alpha = \\pm ||a||_2$ with sign chosen to avoid cancellation\n",
    "* $e_1$ is the standard basis vector of the form $[1 \\quad 0 \\cdots 0]^T$\n",
    "\n",
    "The householder transform of the vector $a$ is $Ha$ computed as:\n",
    "$$\n",
    "Ha = a - 2 \\frac{v^T a}{v^T v} v\n",
    "$$\n",
    "\n",
    "The householder transform of the vector $a$ will zero out all but 1 element."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a Householder transformation on vector a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([2., 1., 2.]).reshape(3, 1)\n",
    "\n",
    "# Compute v = a - \\alpha e_1.\n",
    "alpha = np.linalg.norm(a, ord=2)\n",
    "alpha = -1. * alpha if np.sign(alpha) == 1 else alpha\n",
    "e_1 = np.zeros((a.size, 1))\n",
    "e_1[0] = 1.\n",
    "v = a - alpha * e_1\n",
    "\n",
    "# Compute H = I - 2 ((vv^T) / (v^Tv)).\n",
    "H = np.eye(a.size) - 2. * (np.dot(v, v.T)/np.dot(v.T, v))\n",
    "\n",
    "# Confirm that H is orthogonal.\n",
    "np.testing.assert_almost_equal(np.matmul(H.T, H), np.eye(a.size))\n",
    "\n",
    "# Confirm that H is symmetric.\n",
    "np.testing.assert_almost_equal(H.T, H)\n",
    "\n",
    "# Compute householder transform Ha and compare to explict Ha.\n",
    "Ha = a - 2. * (np.dot(v.T, a)/np.dot(v.T, v)) * v\n",
    "np.testing.assert_almost_equal(Ha, np.matmul(H, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Least Squares Using Householder QR Factorization\n",
    "1. Use Householder transforms to annihilate subdiagonal entries of each successive column.\n",
    "$$\n",
    "H_n \\cdots H_1 A = Q^T A =\n",
    "\\begin{bmatrix}\n",
    "R \\\\\n",
    "0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "  * Use the formula for $Ha$ to compute the *ith* transform rather than matrix multiplication.\n",
    "  * Note that $H_n \\cdots H_1 = Q^T$.\n",
    "  * Note that factorization of $A = QR$ (no transpose) where $H_1 \\cdots H_n = Q$.\n",
    "2. Apply the same set of transformations to right hand side $b$.\n",
    "$$\n",
    "H_n \\cdots H_1 b = Q^T b\n",
    "$$\n",
    "3. Solve for $x$ using backsubstitution.\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "R \\\\\n",
    "0\n",
    "\\end{bmatrix}\n",
    "x \\approxeq Q^T b\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve $Ax = b$ for $x$ where $A$ is $m \\times n$ using householder QR factorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "\n",
    "def householder_qr(A):\n",
    "    \"\"\"\n",
    "    Use householder transformations to factorize A into QR.\n",
    "    \n",
    "    Q is formed from householder transforms H_1 ... H_n I,\n",
    "    but inner loop computes Q^T = H_n ... H_1 I.  \n",
    "    \n",
    "    Since Q is orthogonal Q^T Q = I, return the transpose of \n",
    "    what is computed from the loop to provide H_1 ... H_n I.\n",
    "\n",
    "    Returns orthogonal matrix Q and upper right triangular matrix R.\n",
    "    \"\"\"\n",
    "    m, n = A.shape\n",
    "    Q, R = np.eye(m), np.copy(A)\n",
    "    for k in range(n):  # Columns.\n",
    "        alpha_k = -1. * np.sign(R[k,k]) * np.linalg.norm(R[k:,k])\n",
    "        e_k = np.zeros((m, 1))\n",
    "        e_k[k] = 1.\n",
    "        a_k = np.concatenate((e_k[:k], R[k:,k,np.newaxis]))\n",
    "        v_k = a_k - alpha_k * e_k\n",
    "        beta_k = np.dot(v_k.T, v_k)\n",
    "        Q -= 2.*(np.dot(v_k.T, Q)/beta_k) * v_k\n",
    "        if abs(beta_k) < np.finfo('d').eps:\n",
    "            continue\n",
    "        for j in range(k, n):  # Columns.\n",
    "            gamma_j = np.dot(v_k.T, R[:,j])\n",
    "            R[:,j,np.newaxis] -= (2.*gamma_j/beta_k) * v_k\n",
    "    # Q^T reverses order of transforms as described by docstring.\n",
    "    return Q.T[:,:n], R[:n,:]\n",
    "\n",
    "\n",
    "# Input data $(t_i, b_i)$.\n",
    "m = 5\n",
    "t = np.linspace(-1., 1., m)\n",
    "b = np.array([1., 0.5, 0., 0.5, 2.]).reshape(m, 1)\n",
    "A = np.column_stack((np.ones(m), t, t*t))\n",
    "n = A.shape[1]\n",
    "\n",
    "# Factorize A into QR.\n",
    "Q, R = householder_qr(A)\n",
    "np.testing.assert_almost_equal(A, np.matmul(Q, R))  # Self-check.\n",
    "\n",
    "# Apply the householder transformation to b.\n",
    "c = np.matmul(Q.T, b)\n",
    "\n",
    "# Solve Rx = c for x by back substitution.\n",
    "# NOTE(mmorais): Both R and c must be square.\n",
    "x = la.solve_triangular(R, c[:n], lower=False, unit_diagonal=False)\n",
    " \n",
    "# Compute the squared 2-norm of the residual.\n",
    "resid = y - np.matmul(A, x)\n",
    "sq2norm = np.linalg.norm(resid, ord=2)**2\n",
    "\n",
    "# Compare to the residual returned from np.linalg.lstsq.\n",
    "_, r, _, _ = np.linalg.lstsq(A, b, rcond=None)\n",
    "np.testing.assert_almost_equal(sq2norm, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.06 Givens QR Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each Givens rotation zeroes an element in the subdiagonal of the matrix, forming the R matrix. The concatenation of all the Givens rotations forms the orthogonal Q matrix.\n",
    "\n",
    "Givens rotations are expensive to compute, but unlike the householder transformations they can be parallelized.\n",
    "\n",
    "Givens QR factorization is less frequently used than householder transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.07 Gram-Schmidt QR Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gram-Schmidt Orthogonalization\n",
    "Given vectors $a_1$ and $a_2$ seek orthonormal vectors $q_1$ and $q_2$ having the same span.\n",
    "1. Normalize $a_1$ to obtain $q_1 = a_1 / ||a_1||_2$\n",
    "2. Project $a_2$ onto $q_1$ via $q_2 = a_2 - (q_1^T a_2) q_1$\n",
    "\n",
    "Implementations\n",
    "1. Classical Gram-Schmidt\n",
    "  * Orthonormalizes column-by-column\n",
    "  * Subtracts current $q_k$ from components in preceding columns\n",
    "  * Requires separate storage for $Q$ and $R$\n",
    "2. Modified Gram-Schmidt\n",
    "  * Orthonormalizes column-by-column\n",
    "  * Subtracts current $q_k$ from components in succeeding columns\n",
    "    * $R$ is built up row-by-row\n",
    "    * More numerically stable than Classical Gram-Schmidt\n",
    "  * $A$ can be modified in place to obtain $R$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve $Ax = b$ for $x$ where $A$ is $m \\times n$ using classical Gram-Schmidt QR factorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "\n",
    "def cgs_qr(A):\n",
    "    \"\"\"\n",
    "    Use classical Gram-Schmidt to factorize A into QR.\n",
    "\n",
    "    Returns orthogonal matrix Q and upper right triangular matrix R.\n",
    "    \"\"\"\n",
    "    m, n = A.shape\n",
    "    Q, R = np.eye(m), np.zeros((m, n))\n",
    "    for k in range(n):  # Columns.\n",
    "        Q[:,k] = A[:,k]\n",
    "        # Subtract from current column its' components in preceding.\n",
    "        for j in range(k):  # Columns.\n",
    "            R[j,k] = np.dot(Q[:,j], A[:,k])\n",
    "            Q[:,k] -= R[j,k] * Q[:,j]\n",
    "        R[k,k] = np.linalg.norm(Q[:,k])\n",
    "        if abs(R[k,k]) < np.finfo('d').eps:\n",
    "            break  # Linearly depdendent.\n",
    "        Q[:,k] /= R[k,k]  # Normalize.\n",
    "    return Q[:,:n], R[:n,:]\n",
    "\n",
    "\n",
    "# Input data $(t_i, b_i)$.\n",
    "m = 5\n",
    "t = np.linspace(-1., 1., m)\n",
    "b = np.array([1., 0.5, 0., 0.5, 2.]).reshape(m, 1)\n",
    "A = np.column_stack((np.ones(m), t, t*t))\n",
    "n = A.shape[1]\n",
    "\n",
    "# Factorize A into QR.\n",
    "Q, R = cgs_qr(A)\n",
    "np.testing.assert_almost_equal(A, np.matmul(Q, R))  # Self-check.\n",
    "\n",
    "# Apply the Gram-Schmidt transformation to b.\n",
    "c = np.matmul(Q.T, b)\n",
    "\n",
    "# Solve Rx = c for x by back substitution.\n",
    "# NOTE(mmorais): Both R and c must be square.\n",
    "x = la.solve_triangular(R, c[:n], lower=False, unit_diagonal=False)\n",
    "\n",
    "# Compute the squared 2-norm of the residual.\n",
    "resid = y - np.matmul(A, x)\n",
    "sq2norm = np.linalg.norm(resid, ord=2)**2\n",
    "\n",
    "# Compare to the residual returned from np.linalg.lstsq.\n",
    "_, r, _, _ = np.linalg.lstsq(A, b, rcond=None)\n",
    "np.testing.assert_almost_equal(sq2norm, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve $Ax = b$ for $x$ where $A$ is $m \\times n$ using modified Gram-Schmidt QR factorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "\n",
    "def mgs_qr(A):\n",
    "    \"\"\"\n",
    "    Use modified Gram-Schmidt to factorize A into QR.\n",
    "\n",
    "    Returns orthogonal matrix Q and upper right triangular matrix R.\n",
    "    \"\"\"\n",
    "    m, n = A.shape\n",
    "    Q, R, AA = np.eye(m), np.zeros((m, n)), np.copy(A)\n",
    "    for k in range(n):  # Columns.\n",
    "        R[k,k] = np.linalg.norm(AA[:,k])\n",
    "        if abs(R[k,k]) < np.finfo('d').eps:\n",
    "            break  # Linearly depdendent.\n",
    "        Q[:,k] = AA[:,k] / R[k,k]  # Normalize.\n",
    "        # Subtract from succeeding columns the components in current.\n",
    "        for j in range(k+1,n): # Columns.\n",
    "            R[k,j] = np.dot(Q[:,k], AA[:,j])\n",
    "            AA[:,j] -= R[k,j] * Q[:,k]\n",
    "    return Q[:,:n], R[:n,:]\n",
    "\n",
    "\n",
    "# Input data $(t_i, b_i)$.\n",
    "m = 5\n",
    "t = np.linspace(-1., 1., m)\n",
    "b = np.array([1., 0.5, 0., 0.5, 2.]).reshape(m, 1)\n",
    "A = np.column_stack((np.ones(m), t, t*t))\n",
    "n = A.shape[1]\n",
    "\n",
    "# Factorize A into QR.\n",
    "Q, R = mgs_qr(A)\n",
    "np.testing.assert_almost_equal(A, np.matmul(Q, R))  # Self-check.\n",
    "\n",
    "# Apply the Gram-Schmidt transformation to b.\n",
    "c = np.matmul(Q.T, b)\n",
    "\n",
    "# Solve Rx = c for x by back substitution.\n",
    "# NOTE(mmorais): Both R and c must be square.\n",
    "x = la.solve_triangular(R, c[:n], lower=False, unit_diagonal=False)\n",
    "\n",
    "# Compute the squared 2-norm of the residual.\n",
    "resid = y - np.matmul(A, x)\n",
    "sq2norm = np.linalg.norm(resid, ord=2)**2\n",
    "\n",
    "# Compare to the residual returned from np.linalg.lstsq.\n",
    "_, r, _, _ = np.linalg.lstsq(A, b, rcond=None)\n",
    "np.testing.assert_almost_equal(sq2norm, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.08 Rank Deficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If rank(A) < n, then QR factorization exists, but yields singular upper triangular factor R.\n",
    "\n",
    "#### QR with Column Pivoting\n",
    "Instead of processing columns in natural order, select for reduction at each stage column of remaining unreduced submatrix having maximum Euclidean norm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.09 Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVD of a $m \\times n$ matrix $A$ is given by:\n",
    "$$\n",
    "A = U \\Sigma V^T\n",
    "$$\n",
    "where\n",
    "* $U$ is an $m \\times m$ orthogonal matrix\n",
    "  * Columns of $U$ referred to as **left singular vectors**\n",
    "* $\\Sigma$ is an $m \\times n$ diagonal matrix\n",
    "  * Diagonal entries $\\sigma_i$ referred to as **singular values** of $A$\n",
    "  * Typically decreasing order $\\sigma_1 \\geq \\sigma_2 \\geq \\sigma_3 \\cdots \\sigma_n$\n",
    "* $V$ is an $n \\times n$ orthogonal matrix\n",
    "  * Columns of $V$ referred to as **right singular vectors**\n",
    "\n",
    "#### Applications\n",
    "* Minimum norm solution to $Ax \\approxeq b$\n",
    "$$\n",
    "x = \\sum_{\\sigma_i \\neq 0} \\frac{u_i^T b}{\\sigma_i} b\n",
    "$$\n",
    "* Euclidean matrix norm\n",
    "$$\n",
    "||A||_2 = \\sigma_{\\text{max}}\n",
    "$$\n",
    "* Euclidean condition number\n",
    "$$\n",
    "\\text{cond}_2(A) = \\frac{\\sigma_{\\text{max}}}{\\sigma_{\\text{min}}}\n",
    "$$\n",
    "* Rank of matrix = number of nonzero singular values\n",
    "\n",
    "#### Pseudoinverse\n",
    "The pseudoinverse $A^+$ of a $m \\times n$ matrix $A$ is given by:\n",
    "$$\n",
    "A^+ = V \\Sigma^+ U^T\n",
    "$$\n",
    "where\n",
    "* $\\Sigma^+$ is a diagonal matrix with reciprocal and transpose of singular values.\n",
    "* $A^+$ always exists, even when matrix is not full rank.\n",
    "* If $A$ is square and nonsingular, then $A^+ = A^{-1}$\n",
    "* Minimum norm solution to $Ax \\approxeq b$ given by $x = A^+ b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Least Squares\n",
    "Ordinary least squares (OLS) is applicable when $b$ is subject to random error but $A$ is known accurately.\n",
    "\n",
    "Total least squares (TLS) is applicable when $b$ and $A$ are subject to random error.\n",
    "* Unlike OLS, we minimize orthogonal distances rather than vertical distances.\n",
    "* TLS is computed from SVD of $[A | b]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decompose A into $U$, $\\Sigma$, and $V$ using numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes U: (4, 4)  S: (3,)  V^T: (3, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.arange(1, 13).reshape(4,3)\n",
    "\n",
    "# Factorize A into SVD.\n",
    "U, Sigma, VT = np.linalg.svd(A)\n",
    "print(\"shapes U:\", U.shape, \" S:\", Sigma.shape, \" V^T:\", VT.shape)\n",
    "\n",
    "# Reconstruct A from factorization.\n",
    "np.testing.assert_almost_equal(A, \n",
    "    np.matmul(U[:,:Sigma.shape[0]] * Sigma, VT))\n",
    "\n",
    "# Compare sigma_max to Euclidean norm.\n",
    "np.testing.assert_almost_equal(np.linalg.norm(A, ord=2), np.max(Sigma))\n",
    "\n",
    "# Compare sigma_max / sigma_min to Euclidean condition number.\n",
    "np.testing.assert_allclose(np.linalg.cond(A, p=2), \n",
    "                           np.max(Sigma)/np.min(Sigma))\n",
    "\n",
    "# Compare number of nonsingular values to rank.\n",
    "# NOTE: Comparing against eps insufficient, need larger tolerance.\n",
    "np.testing.assert_equal(np.linalg.matrix_rank(A), \n",
    "                        np.where(Sigma > 1e-14)[0].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve $Ax = b$ for $x$ where $A$ is $m \\times n$ using SVD factorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes U: (5, 5)  S: (3,)  V^T: (3, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Input data $(t_i, b_i)$.\n",
    "m = 5\n",
    "t = np.linspace(-1., 1., m)\n",
    "b = np.array([1., 0.5, 0., 0.5, 2.]).reshape(m, 1)\n",
    "A = np.column_stack((np.ones(m), t, t*t))\n",
    "n = A.shape[1]\n",
    "\n",
    "# Factorize A into SVD.\n",
    "U, Sigma, VT = np.linalg.svd(A)\n",
    "print(\"shapes U:\", U.shape, \" S:\", Sigma.shape, \" V^T:\", VT.shape)\n",
    "\n",
    "# Compute \\Sigma^+ by taking reciprocal of singular values.\n",
    "Sigmaplus = np.diag(1./Sigma).T\n",
    "\n",
    "# Compute the pseudoinverse A^+ = V \\Sigma^+ U^T.\n",
    "Aplus = np.matmul(np.matmul(VT.T, Sigmaplus), U[:,:Sigma.shape[0]].T)\n",
    "\n",
    "# Solve for x using x = A^+ b.\n",
    "x = np.matmul(Aplus, b)\n",
    "\n",
    "# Compute the squared 2-norm of the residual.\n",
    "resid = y - np.matmul(A, x)\n",
    "sq2norm = np.linalg.norm(resid, ord=2)**2\n",
    "\n",
    "# Compare to the residual returned from np.linalg.lstsq.\n",
    "_, r, _, _ = np.linalg.lstsq(A, b, rcond=None)\n",
    "np.testing.assert_almost_equal(sq2norm, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.10 Comparison of Methods for Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Method | Complexity | Notes |\n",
    "|--------|------------|-------|\n",
    "| normal equations | $n^3/6$ | unstable |\n",
    "| Householder QR | $n^3/3$ | stable |\n",
    "| SVD | $n^3$ | robust, but expensive |\n",
    "\n",
    "Comparing relative error of solutions by method.\n",
    "* Normal equations method breaks down when condition number is $> 1/\\sqrt{\\epsilon_{\\text{mach}}}$.\n",
    "$$\n",
    "\\text{rel. error} = [\\text{cond}(A)]^2\n",
    "$$\n",
    "* Householder method is best possible esp. when residual is small.\n",
    "$$\n",
    "\\text{rel. error} = \\text{cond}(A) + ||r||_2 [\\text{cond}(A)]^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
